{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45b6b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc759b",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "82432e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToTensor()\n",
    "train_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=True, transform=trans, download=True)\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"../data\", train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "484df219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(i):  #@save\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return text_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba8d7ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[0], cmap='gray')\n",
    "plt.title(get_label(train_data.targets[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ecf397da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1ad89fcc040>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1ad89fccaf0>}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = {\n",
    "    'train' : data.DataLoader(train_data, \n",
    "                              batch_size=100, \n",
    "                              shuffle=True, \n",
    "                              num_workers=1),\n",
    "    \n",
    "    'test'  : data.DataLoader(test_data, \n",
    "                              batch_size=100, \n",
    "                              shuffle=True, \n",
    "                              num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1921be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for X, y in loaders['test']:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21ce8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66ae2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 28\n",
    "# 序列长度\n",
    "input_size = 28\n",
    "# 每个序列的输入数\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6d7c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(28, 128, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        # Passing in the input and hidden state into the model and  obtaining outputs\n",
    "        out, hidden = self.rnn(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "       \n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a534726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80f44242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d7a7b272",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m                 \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], Step [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     20\u001b[0m                        \u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, total_step, loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epochs, model, loaders)\u001b[0m\n\u001b[0;32m      8\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, sequence_length, input_size)\n\u001b[0;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Passing in the input and hidden state into the model and  obtaining outputs\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#Reshaping the outputs such that it can be fit into the fully connected layer\u001b[39;00m\n\u001b[0;32m     19\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:534\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    532\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mhx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    536\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor batched 3-D input, hx should also be 3-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    537\u001b[0m max_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "def train(num_epochs, model, loaders):\n",
    "        \n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            images = images.reshape(-1, sequence_length, input_size)\n",
    "            labels = labels\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                \n",
    "\n",
    "train(num_epochs, model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41537c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in loaders['test']:\n",
    "    images = images.reshape(-1, sequence_length, input_size)\n",
    "    outputs = model(images)\n",
    "    print(outputs.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db353021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 85.74 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loaders['test']:\n",
    "        images = images.reshape(-1, sequence_length, input_size)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total = total + labels.size(0)\n",
    "        correct = correct + (predicted == labels).sum().item()\n",
    "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af587339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
